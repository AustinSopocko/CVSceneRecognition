\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{COMP3204: Scene Recognition}

\author{Adethya Srinivasan\\
University of Southampton\\
as37g23@soton.ac.uk\\
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
\and
Second Author\\
Institution2\\
First line of institution2 address\\
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
Write an abstract???
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Run 1}

\section{Run 2}

\subsection{Project Overview}
The pipeline consists of four stages:
\begin{enumerate}
    \item \textbf{Feature Extraction:} Breaking images into small pixel patches.
    \item \textbf{Vocabulary Building:} Learning a dictionary of common visual patterns using K-Means.
    \item \textbf{Quantization:} Converting images into fixed-length histograms based on the vocabulary.
    \item \textbf{Classification:} Using Linear Support Vector Machines (SVMs) to predict the scene category.
\end{enumerate}

\subsection{Detailed Pipeline Steps}

\subsubsection{Step 1: Feature Extraction}
\begin{itemize}
    \item \textbf{Dense Sampling:}
    \begin{itemize}
        \item We use an $8 \times 8$ patch with a stride length of $4$.
    \end{itemize}
    \item \textbf{Vectorization:}
    \begin{itemize}
        \item The $8 \times 8$ pixel grid is flattened into a 1-dimensional vector of size 64 ($8 \times 8 = 64$).
    \end{itemize}
    \item \textbf{Patch Normalisation:}
    \begin{itemize}
        \item We subtract the mean of each patch from itself (mean-centring).
        \item We divide the vector by its $L_2$ norm. This scales the vector so it has unit length.
    \end{itemize}
\end{itemize}

\subsubsection{Step 2: Vocabulary Building (K-Means Clustering)}
We use K-Means to create a Bag of Visual Words (BoVW).

\begin{itemize}
    \item \textbf{Sampling:} To manage memory usage, we take a random subset of patches from the training images.
    \item \textbf{Clustering (K-Means):}
    \begin{itemize}
        \item We perform K-Means for a single $k$ value.
    \end{itemize}
    \item The final $k$ cluster centers become our \textbf{``Visual Words''}.
\end{itemize}

\subsubsection{Step 3: Quantization (Image Representation)}
We translate every image into a single feature vector of length $k$.

\begin{enumerate}
    \item \textbf{Patch Extraction:} Extract all $8 \times 8$ patches from the image.
    \item \textbf{Nearest Neighbor Assignment:} Each patch is assigned to the cluster of the closest visual word.
    \item \textbf{Histogram Generation:} We count how many patches were assigned to each word to construct a histogram.
    \item \textbf{Histogram Normalisation:} We normalise the resulting histogram.
\end{enumerate}

\subsubsection{Step 4: Classification (Linear SVM)}
We now have a dataset where every image is represented by a $k$-dimensional vector.

\begin{itemize}
    \item \textbf{Algorithm:} Linear Support Vector Machine.
    \item \textbf{Strategy: One-vs-All (OvA):} We train 15 separate one-vs-all classifiers - one for each class.
    \item \textbf{Prediction:}
    \begin{itemize}
        \item When testing a new image, all 15 classifiers output a confidence score.
        \item The class associated with the highest confidence score is selected as the final prediction.
    \end{itemize}
    \item \textbf{Training Accuracy:} We calculate the training accuracy.
    \item \textbf{Optimising:} We compare this to the existing best training accuracy and/or re-run K-Means for a different $k$ value (we test for $k$ values in the range $[475, 525]$) until all values in the range have been tested.
    \item \textbf{Output:} We retrieve the optimal $k$ value and use this $k$ value on the testing data provided.
\end{itemize}



\section{Run 3}





{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
